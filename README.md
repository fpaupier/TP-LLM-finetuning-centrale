# TP LLM finetuning Centrale

![Python3.13](https://img.shields.io/badge/python-3.13-blue)

**Cours INFOIA - Informatique durable | DurÃ©e : 2h**

## Objectifs

### Objectifs pÃ©dagogiques

- Comprendre la gÃ©nÃ©ration de datasets d'instruction synthÃ©tiques
- DÃ©couvrir les techniques de fine-tuning PeFT avec l'exemple LoRA
- Apprendre Ã  utiliser les bibliothÃ¨ques usuels de training / infÃ©rence (vLLM, unsloth, Hugging Face Hub)
- DÃ©velopper les bonnes pratiques de documentation (model cards)

### Organisation

Ce TP est composÃ© de 2 parties

- la Partie 1 - constitution d'un dataset synthÃ©tique
    - _C.f._ [01_synthetic_dataset_generation.ipynb](notebooks/01_synthetic_dataset_generation.ipynb)
- la Partie 2 - fine-tuning avec LoRA
    - _C.f._ [02_lora_finetuning](notebooks/02_lora_finetuning.ipynb)

> [!NOTE]  
> Si vous avez dÃ©jÃ  un dataset d'intÃ©rÃªt pour votre sujet, vous pouvez commencer directement dans le
> notebook [02_lora_finetuning](notebooks/02_lora_finetuning.ipynb).
> Vous pourrez alors prendre plus de temps pour ajuster les diffÃ©rents paramÃ¨tres d'entrainements.

## Getting started

Ce repo utilise `uv` en gestionnaire de paquets.
Voir [astral doc](https://docs.astral.sh/uv/getting-started/installation/) pour l'installation.

### 1. Configuration initiale

```bash
# Cloner le projet
git clone git@github.com:fpaupier/TP-LLM-finetuning-centrale.git
cd TP-LLM-finetuning-centrale

# CrÃ©er votre branche
git checkout -b "votre-nom-de-branche"

# VÃ©rifier la disponibilitÃ© hardware
nvidia-smi  # Vous devez voir votre GPU 
```

## Ressources utiles

### Ressources supplÃ©mentaires :

- ğŸ“– [Documentation Unsloth](https://github.com/unslothai/unsloth)
- ğŸ“– [Guide LoRA/QLoRA](https://huggingface.co/blog/peft)
- ğŸ“– [Best Practices Model Cards](https://huggingface.co/docs/hub/model-cards)
- ğŸ“– [vLLM Documentation](https://docs.vllm.ai/en/stable/)

### DÃ©fis bonus (optionnels) :

- Tester d'autres templates d'instruction
- Comparer diffÃ©rents rangs LoRA (8, 16, 32)
- Ã‰valuer quantitativement avec des benchmarks
- Essayer le multi-GPU avec tensor parallelism pour accÃ©lÃ©rer l'entraÃ®nement

---

## Support

### Ressources de debug :

- ğŸ“‹ **Logs vLLM** : consultez la console oÃ¹ vous avez lancÃ© le serveur
- ğŸ” **Logs Jupyter**
- ğŸ® **Monitoring GPU** : `watch -n1 nvidia-smi` dans un terminal
